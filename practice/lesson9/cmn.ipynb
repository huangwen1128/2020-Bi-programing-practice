{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 844,
     "status": "ok",
     "timestamp": 1606661698597,
     "user": {
      "displayName": "huang wen",
      "photoUrl": "",
      "userId": "13725836683345626330"
     },
     "user_tz": -480
    },
    "id": "NTl9iL8s0Z7P",
    "outputId": "38d0b378-68a3-4698-afe9-5bb7641d7c51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "os.chdir(\"./drive/My Drive/workspaces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1687,
     "status": "ok",
     "timestamp": 1606661699447,
     "user": {
      "displayName": "huang wen",
      "photoUrl": "",
      "userId": "13725836683345626330"
     },
     "user_tz": -480
    },
    "id": "ObPTyAS6__yt"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "# 使用GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SOS_token = 0\n",
    "EOS_token = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1683,
     "status": "ok",
     "timestamp": 1606661699448,
     "user": {
      "displayName": "huang wen",
      "photoUrl": "",
      "userId": "13725836683345626330"
     },
     "user_tz": -480
    },
    "id": "wAnbDmGAALgs"
   },
   "outputs": [],
   "source": [
    "# 主要用于储存单词与id的映射\n",
    "class Vocabulary(object):\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {0: \"<SOS>\", 1: \"<EOS>\", -1: \"<unk>\"}\n",
    "        self.idx = 2 # Count SOS and EOS\n",
    "\n",
    "    # 记录word和id之间的映射\n",
    "    def add_word(self, word):\n",
    "        if not word in self.word2idx:\n",
    "            self.word2idx[word] = self.idx\n",
    "            self.idx2word[self.idx] = word\n",
    "            self.idx += 1\n",
    "            \n",
    "    # 将句子进行分词，添加每个单词与id的映射\n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split():\n",
    "            self.add_word(word)\n",
    "    \n",
    "    # 得到某个单词的id\n",
    "    def __call__(self, word):\n",
    "        if not word in self.word2idx:\n",
    "            return -1\n",
    "        return self.word2idx[word]\n",
    "    \n",
    "    # vaocabulary的容量\n",
    "    def __len__(self):\n",
    "        return self.idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1679,
     "status": "ok",
     "timestamp": 1606661699450,
     "user": {
      "displayName": "huang wen",
      "photoUrl": "",
      "userId": "13725836683345626330"
     },
     "user_tz": -480
    },
    "id": "VnG1lGcaAkzB"
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        # to do\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.maxlen = 10\n",
    "        #output_size就是输出语言的所有单次的数量，hidden_size就是GRU网络隐藏层的节点数\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        #Linear全连接层，将gru隐藏层与输出层做关联，输入的目标语言单次个数为output_size\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        #通过Logsoftmax函数，就把最大值的索引作为生成目标单次的ID\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    #输入：当前的seq_input, 以及上一时刻的hidden\n",
    "    #输出：对应语言的output id，当前时刻的hidden\n",
    "    def forward(self, seq_input, hidden):\n",
    "        # to do\n",
    "        #输入一个单词id， Embedding将它转化为词向量（hidden_size）\n",
    "        output = self.embedding(seq_input).view(1,1,-1)\n",
    "        output= F.relu(output)\n",
    "        output,hidden = self.gru(output, hidden)\n",
    "        #print(output[0])\n",
    "        #通过全连接层 + softmax层， 找到对应的输出词的ID\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    # pre_hidden即公式中所谓的固定C向量\n",
    "    def sample(self, pre_hidden):\n",
    "        # to do\n",
    "        #定义input\n",
    "        inputs = torch.tensor([SOS_token],device=device)\n",
    "        hidden = pre_hidden\n",
    "        #输出结果记录res\n",
    "        res = [SOS_token]\n",
    "        #循环编码\n",
    "        for i in range(self.maxlen):\n",
    "          #self = self.forword\n",
    "          #输入： 当前的输入和上一时刻隐藏层状态\n",
    "          #输出： 对应语言的output，当前时刻hidden\n",
    "          output,hidden = self(inputs, hidden)\n",
    "          #获取最大值的索引作为生成单词的id\n",
    "          topv, topi = output.topk(1)\n",
    "          #判断是否为结束符\n",
    "          if topi.item() == EOS_token:\n",
    "            res.append(EOS_token)\n",
    "            break\n",
    "          else:\n",
    "            res.append(topi.item())\n",
    "          #将生成的topi 作为下一时刻的输入\n",
    "          inputs = topi.squeeze().detach()\n",
    "        return res\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1670,
     "status": "ok",
     "timestamp": 1606661699450,
     "user": {
      "displayName": "huang wen",
      "photoUrl": "",
      "userId": "13725836683345626330"
     },
     "user_tz": -480
    },
    "id": "FxD9MgHNAqP0"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    # 在构造函数内定义了一个Embedding层和一GRU层，\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        # to do\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        #Enbedding层定义传入了一个input_size和一个hidden_size\n",
    "        #input_size输入语言的所有单词个数\n",
    "        #hidden_size就是LSMT/GRU网络隐藏层的节点数\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    # 前向传播\n",
    "    def forward(self, input, hidden):\n",
    "        # to do\n",
    "        #输入一个单词id，Embedding将它转为词向量（hidden_size）\n",
    "        #pytorch中的GRU输入（seq_len,batch,input_size）\n",
    "        embedded = self.embedding(input).view(1,1,self.hidden_size)\n",
    "        #将enbedding向量作为GRU的输入，最终得到一个输出和隐藏层的状态\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        #在这个简单的seq2seq中，encoder编码器只需要输入隐藏层即可\n",
    "        return hidden\n",
    "    \n",
    "    # 最终执行函数\n",
    "    def sample(self,seq_list):\n",
    "        # to do\n",
    "        word_inds = torch.LongTensor(seq_list).to(device)\n",
    "        #得到初始化h0\n",
    "        h =self.initHidden()\n",
    "        for word_tensor in word_inds:\n",
    "          #前向传播需要两个参数，一个是输入，一个是前一时刻的hidden\n",
    "          h = self.forward(word_tensor, h)\n",
    "        return h\n",
    "\n",
    "    # 初始化第一层的h0，随机生成一个\n",
    "    def initHidden(self):\n",
    "        # to do\n",
    "        return torch.zeros(1,1,self.hidden_size, device=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2498,
     "status": "ok",
     "timestamp": 1606662725755,
     "user": {
      "displayName": "huang wen",
      "photoUrl": "",
      "userId": "13725836683345626330"
     },
     "user_tz": -480
    },
    "id": "yqRQuNYuq4pj",
    "outputId": "9501fa7b-736b-45a2-947e-287946b59bab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Hi .', '嗨 。'], ['Hi .', '你好 。'], ['Run .', '你 用 跑 的 。'], ['Wait !', '等等 ！'], ['Wait !', '等 一下 ！'], ['Hello !', '你好 。'], ['I try .', '让 我 来 。'], ['I won !', '我 赢 了 。'], ['Oh no !', '不会 吧 。'], ['Cheers !', '乾杯   !'], ['Got it ?', '你 懂 了 吗 ？'], ['He ran .', '他 跑 了 。'], ['Hop in .', '跳进来 。'], ['I quit .', '我 退出 。'], [\"I'm OK .\", '我 沒事 。'], ['Listen .', '听 着 。'], ['No way !', '不 可能 ！'], ['No way !', '没门 ！'], ['Really ?', '你 确定 ？'], ['Try it .', '试试 吧 。'], ['We try .', '我们 来 试试 。'], ['Why me ?', '为什么 是 我 ？'], ['Ask Tom .', '去 问 汤姆 。'], ['Awesome !', '好棒 ！'], ['Be calm .', '冷静 点 。'], ['Be fair .', '公平 点 。'], ['Be kind .', '友善 点 。'], ['Be nice .', '和 气点 。'], ['Be nice .', '友善 点 。'], ['Call me .', '联系 我 。'], ['Call us .', '联系 我们 。'], ['Come in .', '进来 。'], ['Get Tom .', '找到 汤姆 。'], ['Get out !', '滾 出去 ！'], ['Get out !', '出去 ！'], ['Go away !', '走開 ！'], ['Go away !', '滾 ！'], ['Go away .', '走開 ！'], ['Go home .', '回家吧 。'], ['Goodbye !', '再见 ！'], ['Goodbye !', '告辞 ！'], ['Hang on !', '坚持 。'], ['Hang on !', '等 一下 ！'], ['Hang on .', '坚持 。'], ['He came .', '他来 了 。'], ['He runs .', '他 跑 。'], ['Help me .', '帮 我 一下 。'], ['Help us .', '帮帮 我们 吧 ！'], ['Hold on .', '坚持 。'], ['Hug Tom .', '抱抱 汤姆 ！'], ['Hug Tom .', '请 抱紧 汤姆 。'], ['I agree .', '我 同意 。'], [\"I'm ill .\", '我 生病 了 。'], [\"I'm old .\", '我 老 了 。'], [\"I'm wet .\", '我 濕 了 。'], [\"It's OK .\", '没关系 。'], [\"It's me .\", '是 我 。'], ['Join us .', '来 加入 我们 吧 。'], ['Keep it .', '留着 吧 。'], ['Kiss me .', '吻 我 。'], ['Perfect !', '完美 ！'], ['See you .', '再见 ！'], ['Shut up !', '閉嘴 ！'], ['Skip it .', '不管 它 。'], ['Take it .', '拿走 吧 。'], ['Wake up !', '醒醒 ！'], ['Wash up .', '去 清洗 一下 。'], ['We know .', '我们 知道 。'], ['Welcome .', '欢迎 。'], ['Who won ?', '谁 赢 了 ？'], ['Why not ?', '为什么 不 ？'], ['You run .', '你 跑 。'], ['Back off .', '往 后退 点 。'], ['Be still .', '静静的 ， 别动 。'], ['Beats me .', '我 一无所知 。'], ['Cuff him .', '把 他 铐 上 。'], ['Drive on .', '往前 开 。'], ['Get away !', '走開 ！'], ['Get away !', '滾 ！'], ['Get down !', '趴下 ！'], ['Get lost !', '滾 ！'], ['Get real .', '醒醒 吧 。'], ['Good job !', '做得好 ！'], ['Good job !', '干 的 好 ！'], ['Grab Tom .', '抓住 汤姆 。'], ['Grab him .', '抓住 他 。'], ['Have fun .', '玩得 開心 。'], ['He tries .', '他来 试试 。'], ['How cute !', '多 可爱 啊 ！'], ['Humor me .', '你 就 随 了 我 的 意 吧 。'], ['Hurry up .', '趕快   !'], ['Hurry up .', '快点 ！'], ['Hurry up .', '快点 。'], ['I forgot .', '我 忘 了 。'], ['I resign .', '我 放弃 。'], [\"I'll pay .\", '我來 付錢 。'], [\"I'm busy .\", '我 很 忙 。'], [\"I'm cold .\", '我 冷 。'], [\"I'm fine .\", '我 很 好 。'], [\"I'm full .\", '我 吃 飽 了 。'], [\"I'm lost .\", '我 迷失 了 。'], [\"I'm sick .\", '我 生病 了 。'], [\"I'm sick .\", '我病 了 。'], [\"I'm tall .\", '我 个子 高 。'], ['Leave me .', '让 我 一个 人 呆 会儿 。'], [\"Let's go !\", '走 吧 。'], [\"Let's go !\", '我們 開始 吧 ！'], [\"Let's go !\", '我們 走 吧   !'], ['Look out !', '当心 ！'], ['Say what ?', '啥 ？'], ['She runs .', '她 跑 。'], ['Stand up .', '起立 。'], ['Terrific !', '很棒 ！'], ['They won .', '他们 赢 了 。'], ['Tom died .', '汤姆 去世 了 。'], ['Tom lied .', '汤姆 说谎 了 。'], ['Tom quit .', '汤姆 不干 了 。'], ['Tom swam .', '汤姆 游泳 了 。'], ['Trust me .', '相信 我 。'], ['Try hard .', '努力 。'], ['Try some .', '试试 吧 。'], ['Who died ?', '谁 死 了 ？'], ['Birds fly .', '鳥類 飛行 。'], ['Call home !', '打电话 回家 ！'], ['Calm down .', '冷静 点 。'], ['Catch him .', '抓住 他 。'], ['Come home .', '回家吧 。'], ['Cool down .', '冷静 点 。'], ['Do it now .', '現在 就 做 。'], ['Dogs bark .', '狗会 叫 。'], [\"Don't cry .\", '别哭 。'], ['Excuse me .', '对不起 。'], ['Fantastic !', '好棒 ！'], ['Fantastic !', '很棒 ！'], ['Feel this .', '来 感受一下 这个 。'], ['Follow me .', '请 跟我来 。'], ['Follow us .', '请 跟着 我们 。'], ['Good luck .', '祝你好运 。'], ['Grab that .', '抓住 那个 。'], ['Grab this .', '抓住 这个 。'], [\"He's a DJ .\", '他 是 一个   DJ   。'], [\"He's lazy .\", '他 很 懒 。'], ['Hold fire .', '停火 。'], ['How awful !', '太 可怕 了 。'], ['How weird !', '多怪 啊 ！'], ['I am cold .', '我 冷 。'], ['I am lost .', '我 迷失 了 。'], ['I am okay .', '我 沒事 。'], ['I am sick .', '我 生病 了 。'], ['I am tall .', '我 个子 高 。'], ['I clapped .', '我 拍手 。'], ['I get you .', '我 了解 你 。'], ['I give up .', '我 放弃 。'], ['I hope so .', '我 希望 如此 。'], ['I laughed .', '我 笑 了 。'], ['I promise .', '我 向 你 保证 。'], ['I saw Tom .', '我 看見 湯姆 了 。'], ['I was shy .', '我 害羞 。'], [\"I'll swim .\", '我要 游泳 。'], [\"I'm a man .\", '我 是 个 男人 。'], [\"I'm bored .\", '我覺 得 很 無聊 。'], [\"I'm right .\", '我 是 對 的 。'], [\"I'm sorry .\", '对不起 。'], [\"I'm sorry .\", '我 很 抱歉 。'], [\"I'm young .\", '我 還年 輕 。'], ['Is it far ?', '遠 嗎 ？'], ['It snowed .', '下雪 了 。'], [\"It's 3:30 .\", '3 点半 了 。'], [\"It's cold .\", '天 很 冷 。'], [\"It's free .\", '它 是 免費 的 。'], [\"It's late .\", '很晚 了 。'], [\"It's true .\", '這是 真的 。'], ['Keep them .', '留着 吧 。'], ['Kill them .', '殺 了 他們'], ['Let me in .', '让 我 进去 。'], ['Lie still .', '躺 着 不动 。'], ['Look back !', '回头 看 ！'], ['Move over .', '腾 一下 地方 。'], ['Of course !', '當然   !'], ['Of course .', '當然 。'], ['Of course .', '当然 了 。'], ['Oh please !', '噢 拜托 了 ！'], ['Open fire !', '开火 ！'], ['Read this .', '念 这个 。'], ['See above .', '参见 上文 。'], ['She cried .', '她 哭 了 。'], ['She tried .', '她 试过 了 。'], ['She walks .', '她 在 行走 。'], ['Sit tight .', '耐心 等 着 。'], ['Slow down .', '慢一點 。'], ['Stay calm .', '保持 冷靜 。'], ['Stay down !', '趴着 ！'], ['Stop that !', '住手 。'], ['Take care !', '照顾 好 自己 。'], ['Take care .', '照顾 好 自己 。'], ['Thank you .', '谢谢 。'], ['Tom slept .', '汤姆 睡 了 。'], ['Tom swims .', 'Tom 游泳 。'], ['Tom tried .', '湯姆累 了 。'], ['Tom waved .', '汤姆 挥手 了 。']]\n",
      "7863\n",
      "14058\n"
     ]
    }
   ],
   "source": [
    "# 处理句子，将句子转换成Tensor\n",
    "def sentence2tensor(lang, sentence):\n",
    "    indexes = [lang(word) for word in sentence.split()]\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "# 将(input, target)的pair都转换成Tensor\n",
    "def pair2tensor(pair):\n",
    "    input_tensor = sentence2tensor(lan1, pair[0])\n",
    "    target_tensor = sentence2tensor(lan2, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "# 定义句子和Vocabulary类\n",
    "lan1 = Vocabulary() #英文\n",
    "lan2 = Vocabulary() #中文\n",
    "'''\n",
    "data = [['Hi .', '嗨 。'],\n",
    "        ['Hi .', '你 好 。'],\n",
    "        ['Run .', '跑'],\n",
    "        ['Wait !', '等等 ！'],\n",
    "        ['Hello !', '你好 。'],\n",
    "        ['I try .', '让 我 来 。'],\n",
    "        ['I won !', '我 赢 了 。'],\n",
    "        ['I am OK .', '我 沒事 。']]\n",
    "'''\n",
    "data= []\n",
    "import jieba\n",
    "import re\n",
    "\n",
    "with open('cmn.txt', 'r') as file_to_read:\n",
    "  while True:\n",
    "    lines = file_to_read.readline() # 整行读取数据\n",
    "    lan = []\n",
    "    if not lines:\n",
    "      break\n",
    "      pass\n",
    "    lines = lines.replace('.',' .').replace('?',' ?').replace('!', ' !')\n",
    "    #lan = re.split('[.?!。？！]', lines)\n",
    "    split_list = re.split('[\\t]', lines)\n",
    "    lan.append(str(split_list[0]))\n",
    "    lan.append(' '.join(jieba.lcut(split_list[1])))\n",
    "    data.append(lan)\n",
    "\n",
    "print(data[:200])\n",
    "\n",
    "#data = data[17000:23000]\n",
    "\n",
    "for i,j in data:\n",
    "    lan1.add_sentence(i)\n",
    "    lan2.add_sentence(j)\n",
    "print(len(lan1))\n",
    "print(len(lan2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 255787,
     "status": "ok",
     "timestamp": 1606663676668,
     "user": {
      "displayName": "huang wen",
      "photoUrl": "",
      "userId": "13725836683345626330"
     },
     "user_tz": -480
    },
    "id": "IQeyd-CC_e2W",
    "outputId": "9bd997c0-245f-49bf-aef3-cc0310af465c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:5.3036\n",
      "loss:5.2826\n",
      "loss:5.2434\n",
      "loss:5.0593\n",
      "loss:5.0534\n",
      "loss:5.0207\n",
      "loss:4.9904\n",
      "loss:4.9080\n",
      "loss:5.0489\n",
      "loss:4.7266\n",
      "loss:4.8838\n",
      "loss:4.8984\n",
      "loss:4.8424\n",
      "loss:4.7008\n",
      "loss:4.9527\n",
      "loss:4.8370\n",
      "loss:4.9296\n",
      "loss:4.6780\n",
      "loss:4.7004\n",
      "loss:4.8277\n",
      "loss:4.7595\n",
      "loss:4.7596\n",
      "loss:4.7172\n",
      "loss:4.5225\n",
      "loss:4.8812\n",
      "loss:4.9112\n",
      "loss:4.7676\n",
      "loss:4.6990\n",
      "loss:4.7316\n",
      "loss:4.2663\n",
      "loss:4.5004\n",
      "loss:4.7606\n",
      "loss:4.5055\n",
      "loss:4.5443\n",
      "loss:4.4663\n",
      "loss:4.4303\n",
      "loss:4.4698\n",
      "loss:4.6098\n",
      "loss:4.3028\n",
      "loss:4.5600\n",
      "loss:4.3028\n",
      "loss:4.5433\n",
      "loss:4.4860\n",
      "loss:4.3472\n",
      "loss:4.4569\n",
      "loss:4.3465\n",
      "loss:4.1756\n",
      "loss:4.7599\n",
      "loss:4.4549\n",
      "loss:4.3583\n"
     ]
    }
   ],
   "source": [
    "# 定义Encoder和Decoder以及训练的一些参数\n",
    "import random\n",
    "learning_rate = 0.001\n",
    "hidden_size = 512\n",
    "\n",
    "# 将Encoder, Decoder放到GPU\n",
    "encoder = EncoderRNN(len(lan1), hidden_size).to(device)\n",
    "decoder = DecoderRNN(hidden_size, len(lan2)).to(device)\n",
    "# 网络参数 = Encoder参数 + Decoder参数\n",
    "params = list(encoder.parameters()) + list(decoder.parameters())\n",
    "# 定义优化器\n",
    "optimizer = optim.Adam(params, lr=learning_rate)\n",
    "loss = 0\n",
    "# NLLLoss = Negative Log Likelihood Loss\n",
    "criterion = nn.NLLLoss()\n",
    "# 一共训练多次轮\n",
    "turns = 10000\n",
    "print_every = 200\n",
    "print_loss_total = 0\n",
    "# 将数据random choice，然后转换成 Tensor\n",
    "#training_pairs = [pair2tensor(random.choice(data)) for pair in range(turns)]\n",
    "training_pairs = [pair2tensor(random.choice(data)) for pair in range(int(len(data)*0.9))]\n",
    "\n",
    "#print(training_pairs)\n",
    "\n",
    "# 训练过程\n",
    "for turn in range(turns):\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    x, y = training_pairs[turn]\n",
    "    input_length = x.size(0)\n",
    "    target_length = y.size(0)\n",
    "    # 初始化Encoder中的h0\n",
    "    h = encoder.initHidden()\n",
    "    # 对input进行Encoder\n",
    "    for i in range(input_length):\n",
    "        h = encoder(x[i],h)\n",
    "    # Decoder的一个input <sos>\n",
    "    decoder_input = torch.LongTensor([SOS_token]).to(device)\n",
    "    \n",
    "    for i in range(target_length):\n",
    "        decoder_output, h = decoder(decoder_input, h)\n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        decoder_input = topi.squeeze().detach()\n",
    "        #计算loss 预测的decoder_output， 真实值y[i]\n",
    "        loss += criterion(decoder_output, y[i])\n",
    "        if decoder_input.item() == EOS_token:break\n",
    "                \n",
    "    print_loss_total += loss.item()/target_length\n",
    "    if (turn+1) % print_every == 0 :\n",
    "        print(\"loss:{loss:,.4f}\".format(loss=print_loss_total/print_every))\n",
    "        print_loss_total = 0\n",
    "        \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 754,
     "status": "ok",
     "timestamp": 1606664693442,
     "user": {
      "displayName": "huang wen",
      "photoUrl": "",
      "userId": "13725836683345626330"
     },
     "user_tz": -480
    },
    "id": "nVlUXqvu_5vH",
    "outputId": "b5a19989-9a72-4088-a78b-da5229c381d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[288, 229, 354, 1034, 16, 1]\n",
      "<SOS> 我 哪裡 哪裡 哪裡 的 的 ？ <EOS>\n",
      "[372, 537, 1384, 1]\n",
      "<SOS> 这 不是 。 。 <EOS>\n",
      "[378, 1397, 229, 374, 3, 1]\n",
      "<SOS> 这 是 是 的 。 <EOS>\n",
      "[8, 239, 3, 1]\n",
      "<SOS> 我 可以 。 。 <EOS>\n"
     ]
    }
   ],
   "source": [
    "# 测试函数\n",
    "def translate(s):\n",
    "    t = [lan1(i) for i in s.split()]\n",
    "    t.append(EOS_token)\n",
    "    print(t)\n",
    "    f = encoder.sample(t)   # 编码 \n",
    "    s = decoder.sample(f)   # 解码\n",
    "    r = [lan2.idx2word[i] for i in s]    # 根据id得到单词\n",
    "    return ' '.join(r) # 生成句子\n",
    "print(translate('Where is my dad ?'))\n",
    "print(translate('That\\'s very handy'))\n",
    "print(translate('This desk is mine .'))\n",
    "print(translate('I can .'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDZqYuu6mc3Y"
   },
   "source": [
    "从结果上看我觉得seq2seq效果并不理想，是不是可以理解为如果加上attention等机制之后，效果会有所提升？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 828,
     "status": "ok",
     "timestamp": 1606663190067,
     "user": {
      "displayName": "huang wen",
      "photoUrl": "",
      "userId": "13725836683345626330"
     },
     "user_tz": -480
    },
    "id": "vRt0loV7X19H"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOgS+w4TAphb6wVHCnRFew/",
   "collapsed_sections": [],
   "name": "cmn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
