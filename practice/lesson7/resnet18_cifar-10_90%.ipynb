{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"resnet18_cifar-10.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN7hhgMIcmmKfsQKSwpRFzk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"L8PrqUqTvv4R","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599705302407,"user_tz":-480,"elapsed":4622,"user":{"displayName":"huang wen","photoUrl":"","userId":"13725836683345626330"}}},"source":["import torch\n","import torch.nn.functional as F\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","import argparse\n","import torch.optim.lr_scheduler as lr_scheduler\n","\n","class ResidualBlock(nn.Module):\n","    def __init__(self, inchannel, outchannel, stride=1):\n","        super(ResidualBlock, self).__init__()\n","        self.left = nn.Sequential(\n","            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),\n","            nn.BatchNorm2d(outchannel),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(outchannel)\n","        )\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or inchannel != outchannel:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(outchannel)\n","            )\n","\n","    def forward(self, x):\n","        out = self.left(x)\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","class ResNet(nn.Module):\n","    def __init__(self, ResidualBlock, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.inchannel = 64\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","        )\n","        self.layer1 = self.make_layer(ResidualBlock, 64,  2, stride=1)\n","        self.layer2 = self.make_layer(ResidualBlock, 128, 2, stride=2)\n","        self.layer3 = self.make_layer(ResidualBlock, 256, 2, stride=2)\n","        self.layer4 = self.make_layer(ResidualBlock, 512, 2, stride=2)\n","        self.fc = nn.Linear(512, num_classes)\n","\n","    def make_layer(self, block, channels, num_blocks, stride):\n","        strides = [stride] + [1] * (num_blocks - 1)   #strides=[1,1]\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.inchannel, channels, stride))\n","            self.inchannel = channels\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = self.conv1(x)\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.fc(out)\n","        return out\n","\n","\n","def ResNet18():\n","\n","    return ResNet(ResidualBlock)"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gd9yVn7kw-Fu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":124},"executionInfo":{"status":"ok","timestamp":1599705329388,"user_tz":-480,"elapsed":19733,"user":{"displayName":"huang wen","photoUrl":"","userId":"13725836683345626330"}},"outputId":"d3383c81-a20f-47e9-f21e-4041d1f829f1"},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","os.chdir(\"./drive/My Drive/workspaces\")"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","4/4AFaRKBCaiV4qGqvzNTrj4kIDxnaw0i6ZoCtYN6bkrbN5ugin4pno20\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c1rfXWXkv5KG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1599705353761,"user_tz":-480,"elapsed":22733,"user":{"displayName":"huang wen","photoUrl":"","userId":"13725836683345626330"}},"outputId":"bc426209-e018-42da-e42d-e08028cf52c2"},"source":["# 超参数设置\n","EPOCH = 50   #遍历数据集次数\n","pre_epoch = 0  # 定义已经遍历数据集的次数\n","BATCH_SIZE = 128      #批处理尺寸(batch_size)\n","LR = 0.1        #学习率\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),  #先四周填充0，在吧图像随机裁剪成32*32\n","    transforms.RandomHorizontalFlip(),  #图像一半的概率翻转，一半的概率不翻转\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), #R,G,B每层的归一化用到的均值和方差\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","trainset = torchvision.datasets.CIFAR10(root='nas/cifar10', train=True, download=False, transform=transform_train) #训练数据集\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)   #生成一个个batch进行批训练，组成batch的时候顺序打乱取\n","\n","testset = torchvision.datasets.CIFAR10(root='nas/cifar10', train=False, download=False, transform=transform_test)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n","# Cifar-10的标签\n","\n","net = ResNet18().to(device)\n","#criterion = nn.CrossEntropyLoss()  #损失函数为交叉熵，多用于多分类问题\n","optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4) #优化方式为mini-batch momentum-SGD，并采用L2正则化（权重衰减）\n","scheduler = lr_scheduler.StepLR(optimizer, step_size=15,gamma=0.1)\n","net.to(device)"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (layer1): Sequential(\n","    (0): ResidualBlock(\n","      (left): Sequential(\n","        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (shortcut): Sequential()\n","    )\n","    (1): ResidualBlock(\n","      (left): Sequential(\n","        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (shortcut): Sequential()\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): ResidualBlock(\n","      (left): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (shortcut): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): ResidualBlock(\n","      (left): Sequential(\n","        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (shortcut): Sequential()\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): ResidualBlock(\n","      (left): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (shortcut): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): ResidualBlock(\n","      (left): Sequential(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (shortcut): Sequential()\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): ResidualBlock(\n","      (left): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (shortcut): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): ResidualBlock(\n","      (left): Sequential(\n","        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (shortcut): Sequential()\n","    )\n","  )\n","  (fc): Linear(in_features=512, out_features=10, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"RX9zJjtpw251","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1599706857443,"user_tz":-480,"elapsed":1499085,"user":{"displayName":"huang wen","photoUrl":"","userId":"13725836683345626330"}},"outputId":"9a1ff857-9c70-45c1-d979-8aea8e240cc2"},"source":["# 训练\n","for epoch in range(EPOCH):\n","    if scheduler:\n","      scheduler.step()\n","    for i, data in enumerate(trainloader):\n","        inputs, labels = data\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        net.train()\n","        # 前向传播\n","        outputs = net(inputs)\n","        # 计算损失函数\n","        #loss = criterion(outputs, labels)\n","        loss = F.cross_entropy(outputs, labels)\n","        # 清空上一轮梯度\n","        optimizer.zero_grad()\n","        # 反向传播\n","        loss.backward()\n","        # 参数更新\n","        optimizer.step()\n"," \n","    print('epoch{} loss:{:.4f}'.format(epoch+1, loss.item()))\n","    net.eval()                                   #测试模式\n","    with torch.no_grad():             \n","      total_correct = 0                           #预测正确的个数\n","      total_num = 0\n","      for i, data in enumerate(testloader): \n","        inputs, labels = data\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        out = net(inputs)\n","        _, predicted = torch.max(out.data, 1)\n","        total_num += labels.size(0)\n","        total_correct += (predicted == labels).sum().item()                            \n","      print('10000测试图像 准确率:{:.4f}%'.format(100 * total_correct / total_num)) \n","\n","print(\"Finished Traning\")"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["epoch1 loss:1.7551\n","10000测试图像 准确率:37.2100%\n","epoch2 loss:1.4598\n","10000测试图像 准确率:51.6800%\n","epoch3 loss:0.9833\n","10000测试图像 准确率:59.2700%\n","epoch4 loss:1.0116\n","10000测试图像 准确率:63.8800%\n","epoch5 loss:0.8491\n","10000测试图像 准确率:67.9800%\n","epoch6 loss:0.8249\n","10000测试图像 准确率:75.5100%\n","epoch7 loss:0.6565\n","10000测试图像 准确率:68.9100%\n","epoch8 loss:0.5601\n","10000测试图像 准确率:73.5700%\n","epoch9 loss:0.7286\n","10000测试图像 准确率:75.9100%\n","epoch10 loss:0.7084\n","10000测试图像 准确率:74.0800%\n","epoch11 loss:0.5131\n","10000测试图像 准确率:74.3600%\n","epoch12 loss:0.5572\n","10000测试图像 准确率:80.2800%\n","epoch13 loss:0.4434\n","10000测试图像 准确率:76.3700%\n","epoch14 loss:0.5036\n","10000测试图像 准确率:79.5300%\n","epoch15 loss:0.4483\n","10000测试图像 准确率:89.5200%\n","epoch16 loss:0.3143\n","10000测试图像 准确率:89.8700%\n","epoch17 loss:0.1216\n","10000测试图像 准确率:90.1900%\n","epoch18 loss:0.2239\n","10000测试图像 准确率:90.5000%\n","epoch19 loss:0.1323\n","10000测试图像 准确率:90.7000%\n","epoch20 loss:0.1120\n","10000测试图像 准确率:90.7400%\n","epoch21 loss:0.1959\n","10000测试图像 准确率:91.1700%\n","epoch22 loss:0.1968\n","10000测试图像 准确率:90.8000%\n","epoch23 loss:0.1634\n","10000测试图像 准确率:90.9700%\n","epoch24 loss:0.0898\n","10000测试图像 准确率:91.1400%\n","epoch25 loss:0.2117\n","10000测试图像 准确率:91.1600%\n","epoch26 loss:0.1035\n","10000测试图像 准确率:91.1200%\n","epoch27 loss:0.1206\n","10000测试图像 准确率:90.8000%\n","epoch28 loss:0.0704\n","10000测试图像 准确率:90.6700%\n","epoch29 loss:0.0978\n","10000测试图像 准确率:90.7000%\n","epoch30 loss:0.0390\n","10000测试图像 准确率:92.2800%\n","epoch31 loss:0.0457\n","10000测试图像 准确率:92.2800%\n","epoch32 loss:0.1339\n","10000测试图像 准确率:92.4400%\n","epoch33 loss:0.0315\n","10000测试图像 准确率:92.5800%\n","epoch34 loss:0.0561\n","10000测试图像 准确率:92.6000%\n","epoch35 loss:0.0357\n","10000测试图像 准确率:92.4300%\n","epoch36 loss:0.0258\n","10000测试图像 准确率:92.5700%\n","epoch37 loss:0.0423\n","10000测试图像 准确率:92.6200%\n","epoch38 loss:0.0415\n","10000测试图像 准确率:92.4400%\n","epoch39 loss:0.0323\n","10000测试图像 准确率:92.5700%\n","epoch40 loss:0.0216\n","10000测试图像 准确率:92.5300%\n","epoch41 loss:0.0127\n","10000测试图像 准确率:92.6800%\n","epoch42 loss:0.0115\n","10000测试图像 准确率:92.5400%\n","epoch43 loss:0.0147\n","10000测试图像 准确率:92.6000%\n","epoch44 loss:0.0141\n","10000测试图像 准确率:92.4100%\n","epoch45 loss:0.0482\n","10000测试图像 准确率:92.4500%\n","epoch46 loss:0.0430\n","10000测试图像 准确率:92.5700%\n","epoch47 loss:0.0221\n","10000测试图像 准确率:92.5200%\n","epoch48 loss:0.0284\n","10000测试图像 准确率:92.5900%\n","epoch49 loss:0.0199\n","10000测试图像 准确率:92.6600%\n","epoch50 loss:0.0345\n","10000测试图像 准确率:92.5600%\n","Finished Traning\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"glSR35CzjITU","colab_type":"text"},"source":["参照网上的写法说是可以达到90%以上，但实际并没有实现\n","个人理解: 在原始的resnet上，做了些优化：\n","1.原始的7*7的卷积核改为3*3，去掉了最大池化部分，这两部分的修改猜测是因为输入原始图片32*32过小，所以去掉了一些特征提取和降维的处理\n","2.另外对原始数据做了一些预处理，进行随机翻转，正则化，都有助于提升准备率.\n","3.调整LR，EPOCH，BATCH_SIZE等\n","4.问题：训练太慢了，有啥好办法，而且容易断线"]},{"cell_type":"code","metadata":{"id":"DLNMT_CBldCH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1599533147977,"user_tz":-480,"elapsed":1047,"user":{"displayName":"huang wen","photoUrl":"","userId":"13725836683345626330"}},"outputId":"242b1b67-5b64-47b5-f139-39288dbd707b"},"source":["!/opt/bin/nvidia-smi"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/bin/bash: /opt/bin/nvidia-smi: No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xiRwz2kbmjmh","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}