{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "def get_page_content_to_sp(request_url):\n",
    "    #print(request_url)\n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.89 Safari/537.36'}\n",
    "    html = requests.get(request_url, headers=headers, timeout=10)\n",
    "    content = html.text\n",
    "    #print(content)\n",
    "    soup = BeautifulSoup(content, 'html.parser', from_encoding='utf-8')\n",
    "    return soup\n",
    "\n",
    "def get_page_content(request_url):\n",
    "    #print(request_url)\n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.89 Safari/537.36'}\n",
    "    html = requests.get(request_url, headers=headers, timeout=10)\n",
    "    content = html.text\n",
    "    return content\n",
    "\n",
    "def analysis(soup):\n",
    "    temp = soup.find('div', class_='tslb_b')\n",
    "    #df = pd.DataFrame(columns=['投诉编号','投诉品牌','投诉车系','投诉车型','问题简述','典型问题','投诉时间','投诉状态'])\n",
    "    tr_list = temp.find_all('tr')\n",
    "    #print(tr_list[0])\n",
    "    columns = [i.string for i in tr_list[0].find_all('th')]\n",
    "    #print(columns)\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    for tr in tr_list[1:]:\n",
    "        data = [i.string for i in tr.find_all(['td', 'em']) if (i.find('img')) == None ]\n",
    "        df.loc[len(df)] = data\n",
    "    return df\n",
    "\n",
    "def product_covert(x):\n",
    "    problem = ''\n",
    "    for i in x.split(','):\n",
    "        problem += str(type_dict[i]) + ' ' if i in type_dict  else ''\n",
    "    return problem\n",
    "        \n",
    "base_url = 'http://www.12365auto.com/zlts/0-0-0-0-0-0_0-0-0-0-0-0-0-'\n",
    "type_url = 'http://www.12365auto.com/js/cTypeInfo.js?version=' + time.strftime(\"%Y%m%d\", time.localtime()) \n",
    "result = pd.DataFrame()\n",
    "type_info = get_page_content(type_url).split('=')[1]\n",
    "type_js = eval(type_info)\n",
    "type_dict = {}\n",
    "for i in type_js:\n",
    "    for j in i['items']:\n",
    "        type_dict[i['value'] + str(j['id'])] = i['name']+str(':') + j['title']\n",
    "page_num = 10\n",
    "for i in range(page_num):\n",
    "    soup = get_page_content_to_sp(base_url+str(i+1)+'.shtml')\n",
    "    df = analysis(soup)\n",
    "    result = result.append(df)\n",
    "result['典型问题'] = result['典型问题'].apply(lambda x : product_covert(x)) \n",
    "result.head()\n",
    "result.to_csv('车质网数据.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "res = requests.get('http://www.12365auto.com/zlts/0-0-0-0-0-0_0-0-0-0-0-0-0-1.shtml')\n",
    "res_elements = etree.HTML(res.text)\n",
    "table = res_elements.xpath('//table[@class=\"ar_c ar_c1\"]')\n",
    "table = etree.tostring(table[0], encoding='utf-8').decode()\n",
    "df = pd.read_html(table, encoding='utf-8', header=0)[0]\n",
    "df['典型问题'] = df['典型问题'].apply(lambda x : product_covert(x))\n",
    "result.to_csv('车质网数据1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
